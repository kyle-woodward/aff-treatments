{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc904bc-7607-4e66-a384-2fedde5094a8",
   "metadata": {},
   "source": [
    "# AFF - Generating Randomized Treated Landscape Scenarios\n",
    "## Creates Randomized Treatment Scenario Landscapes - exports as ee.Images into an ee.ImageCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e31164-d11e-45d6-98b4-b641623b8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fba20a-6d43-4526-82b5-25e810e70727",
   "metadata": {},
   "source": [
    "## USER INPUT - Review/edit paths to your AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a94304a-b6c8-4a6b-b1b5-a2e4e504ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = ee.FeatureCollection(\"projects/aff-treatments/assets/AllParcels_forSIG\")\n",
    "NIparcels = ee.FeatureCollection(\"projects/aff-treatments/assets/AllNIPParcels_forSIG\")\n",
    "fireshed = ee.FeatureCollection(\"projects/aff-treatments/assets/SonoraFireshed\")\n",
    "parcels_dissolve = ee.FeatureCollection(\"projects/aff-treatments/assets/NIPparcels_dissolve\")\n",
    "\n",
    "aoi = fireshed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f1c00-707f-4c52-a9ea-1c9df7a9e419",
   "metadata": {},
   "source": [
    "## USER INPUT - Review/edit the parameters for the treatment randomization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e4a42d-a671-439d-b1df-68c79f91bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_AREA = 245278 #acres of AOI\n",
    "\n",
    "# range of pct of total areas you want to simulate in scenarios\n",
    "SCENARIO_PCT_RANGE = [0.05,0.6] # make as static list ascending not randomized b/w range\n",
    "\n",
    "# total scenarios to run\n",
    "SCENARIOS = 60 \n",
    "\n",
    "# total number of distinct treatment sizes to use in the scenarios\n",
    "#TRT_SIZE_CLASSES = 3 # currently this is not dynamic, either make dynamic or take out as a User input\n",
    "\n",
    "# distinct acreage units to generate\n",
    "SIZE_CLASSES = [10,40,100,400]  # must be length 4\n",
    "                               \n",
    "\n",
    "# LANDFIRE DIST CODE to assign to all treated pixels\n",
    "DIST_CODE = 222\n",
    "\n",
    "DISTRO = 'norm' # 'log' or 'norm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac271c-9d8e-4efc-922e-64e15148c809",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Required Functions, Run and Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a02463-397f-457f-a4e0-88253ac5c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=random.seed(8)\n",
    "\n",
    "# base python math functions\n",
    "def randn(low,i_sum,k):\n",
    "    \"\"\"Generate k number of floating point numbers adding up to i_sum, with no sample being below low \"\"\"\n",
    "    a = np.random.rand(k) #random floats from uniform distribution\n",
    "    weights = (a/a.sum()*(i_sum-low*k)) # adjust floats to sum to i_sum, with given low val threshold\n",
    "    adjusted = weights+low # sum(adjusted) should == i_sum\n",
    "    return [round(i,4) for i in list(adjusted)]\n",
    "\n",
    "def treatment_math(TOTAL_AREA,DISTRO,SCENARIO_PCT_RANGE,SCENARIOS,SIZE_CLASSES):\n",
    "    \"\"\"Returns the amount of treatment units needed per size class and the radii of the kernel needed for each size class to make the randomized treatment landscape in EE\n",
    "    # args:\n",
    "    # TOTAL_AREA (int): total area of aoi to consider treatments in acres\n",
    "    # DISTRO (str): distribution mode to use, one of: 'log', 'norm'\n",
    "    # SCENARIO_PCT_RANGE (list): min and max range of possible pct treated area floats to be randomly chosen per scenario\n",
    "    # SCENARIOS (int): Total unique scenarios to run\n",
    "    # SIZE_CLASSES (list): distinct acreage sizes to generate - list must be of length 4\n",
    "    \"\"\"\n",
    "    dist_dct = {'log': [0.543,0.326,0.109,0.022], # probabilities of the given SIZE_CLASSES for each defined statistical distribution of treatments with acreages ranging 0-400\n",
    "                'norm': [0.309,0.617,0.062,0.012]}\n",
    "    \n",
    "    # make list of length SCENARIOS with random floating point numbers in the range defined by SCNEARIO_PCT_RANGE (list of different total pct treated scenarios)\n",
    "    scn=[]\n",
    "    trt_areas=[]\n",
    "    trt_props=[]\n",
    "    sizes=[]\n",
    "    units=[]\n",
    "    radii=[]\n",
    "    \n",
    "    for i in list(range(SCENARIOS)):\n",
    "        rnd = round(random.uniform(SCENARIO_PCT_RANGE[0], SCENARIO_PCT_RANGE[1]), 4)\n",
    "        scn.append(rnd)\n",
    "\n",
    "        # compute total area to be treated for each scenario\n",
    "        trt_areas_i = TOTAL_AREA*rnd#scn[i]\n",
    "        trt_areas.append(trt_areas_i)\n",
    "        \n",
    "        pdf_probs = dist_dct[DISTRO] # grab the probabilities assigned to each tretment size class from the distribution dictionary\n",
    "        \n",
    "#         i_prop = [round(p/sum(pdf_probs),4) for p in pdf_probs] # normalize the pdf_probs floats so they sum to 1, so we can use them as percentage of total acreages to treat\n",
    "        i_prop = [round(p*trt_areas_i,4) for p in pdf_probs] # get acreage per size class as (pct of size class in distribution * total area to be treated)\n",
    "        trt_props.insert(i,i_prop)\n",
    "                \n",
    "        units_i = [int(round(j)) for j in list(np.divide(i_prop,SIZE_CLASSES)) ]\n",
    "        units.insert(i,units_i)\n",
    "        \n",
    "        # get approximate radius in meters needed for each size class to make correct-sized treatment units\n",
    "        acres_to_sqm = [int(round(size_i*4027)) for size_i in SIZE_CLASSES] # convert to sq meters for each size class in acreage\n",
    "        radii_i_circle = [int(round(math.sqrt(acreage)/math.pi)) for acreage in acres_to_sqm] # radius of circle: A = pi(r^2)  \n",
    "        radii_i_square = [((math.sqrt(acreage)/2)*0.858) for acreage in acres_to_sqm] # rough square radius is A = (side/2) solve for side (side = sqrt(A) ) Have to use artificial multiplier to get as close to the pct treated as possible\n",
    "        radii.insert(i,radii_i_square)\n",
    "    \n",
    "    return scn,trt_areas,trt_props,units,radii\n",
    "\n",
    "# EE functions\n",
    "def distanceFilter(pts,distance):\n",
    "    withinDistance = distance; ##go with pretty far apart at first\n",
    "\n",
    "    ## From the User Guide: https:#developers.google.com/earth-engine/joins_spatial\n",
    "    ## add extra filter to eliminate self-matches\n",
    "    distFilter = ee.Filter.And(ee.Filter.withinDistance(**{\n",
    "      'distance': withinDistance,\n",
    "      'leftField': '.geo',\n",
    "      'rightField': '.geo', \n",
    "      'maxError': 1\n",
    "    }), ee.Filter.notEquals(**{\n",
    "      'leftField': 'system:index',\n",
    "      'rightField': 'system:index',\n",
    "\n",
    "    }));\n",
    "    \n",
    "    distSaveAll = ee.Join.saveAll(**{\n",
    "                  'matchesKey': 'points',\n",
    "                  'measureKey': 'distance'\n",
    "    });\n",
    "    # Apply the join.\n",
    "    spatialJoined = distSaveAll.apply(pts, pts, distFilter);\n",
    "\n",
    "    # Check the number of matches.\n",
    "    # We're only interested if nmatches > 0.\n",
    "    spatialJoined = spatialJoined.map(lambda f: f.set('nmatches', ee.List(f.get('points')).size()) );\n",
    "    spatialJoined = spatialJoined.filterMetadata('nmatches', 'greater_than', 0);\n",
    "\n",
    "    # The real matches are only half the total, because if p1.withinDistance(p2) then p2.withinDistance(p1)\n",
    "    # Use some iterative logic to clean up\n",
    "    def unpack(l): \n",
    "        return ee.List(l).map(lambda f: ee.Feature(f).id())\n",
    "\n",
    "    def iterator_f(f,list):\n",
    "        key = ee.Feature(f).id()\n",
    "        list = ee.Algorithms.If(ee.List(list).contains(key), list, ee.List(list).cat(unpack(ee.List(f.get('points')))))\n",
    "        return list\n",
    "    \n",
    "    ids = spatialJoined.iterate(iterator_f,ee.List([]))\n",
    "    ##print(\"Removal candidates' IDs\", ids);\n",
    "\n",
    "    # Clean up \n",
    "    cleaned_pts = pts.filter(ee.Filter.inList('system:index', ids).Not());\n",
    "    return cleaned_pts\n",
    "\n",
    "def ee_treatments(units,radii):\n",
    "    units = list(reversed(units)) # we generate treatment units in descending order of size\n",
    "    radii = list(reversed(radii))\n",
    "    \n",
    "    SCALE=30\n",
    "    CRS = 'EPSG:5070'\n",
    "    # Generate Biggest Treatments\n",
    "    ptsBiggest = ee.Image.constant(1).clip(aoi).sample(aoi,SCALE,CRS,None,units[0]+(units[0]*2),seed,True,8,True) # sample pts with a numPoints overshoot \n",
    "    ptsBiggest = distanceFilter(ptsBiggest,radii[0]*2.01).limit(units[0]) # remove pts that are too close to each other,would cause overlap, return required num pts\n",
    "    ptsBiggestSize = ptsBiggest.size() # for debugging\n",
    "    areasBiggest = ptsBiggest.reduceToImage(['constant'],ee.Reducer.first()).unmask(0).clip(aoi).reduceNeighborhood(ee.Reducer.max(),ee.Kernel.square(radii[0],'meters')).eq(1) #convert pts to squares with required radius\n",
    "    # mask prohibiting next set of samples within the overlap zone (Biggest areas plus buffer of twice the Big treatments radius)\n",
    "    areasBiggestmask = areasBiggest.distance(ee.Kernel.euclidean(radii[1]*2,'meters')).gte(0).Not().unmask(1).clip(aoi) # ptsBig cant be within twice their own radius of areasBiggest \n",
    "    \n",
    "    # Generate Big Treatments\n",
    "    ptsBig = areasBiggestmask.selfMask().sample(aoi,SCALE,CRS,None,units[1]+(units[1]*2),seed,True,8,True).map(lambda f: f.set('nd',1)) \n",
    "    ptsBig = distanceFilter(ptsBig,radii[1]*2.01).limit(units[1])\n",
    "    ptsBigSize= ptsBig.size()\n",
    "    areasBig = ptsBig.reduceToImage(['nd'],ee.Reducer.first()).unmask(0).clip(aoi).reduceNeighborhood(ee.Reducer.max(),ee.Kernel.square(radii[1],'meters')).eq(1)\n",
    "    # mask prohibiting Medium pts samples within overlap zone (Biggest and Big areas, plus a buffer of twice the Medium treatments radius)\n",
    "    blend_exp = areasBiggest.add(areasBig).gte(1).distance(ee.Kernel.euclidean(radii[2]*2,'meters')).gte(0).Not().unmask(1).clip(aoi)\n",
    "\n",
    "    # Generate Medium Treatments\n",
    "    ptsMedium = blend_exp.selfMask().sample(aoi,SCALE,CRS,None,units[2]+(units[2]*10),seed,True,8,True).map(lambda f: f.set('nd',1))\n",
    "    ptsMedium = distanceFilter(ptsMedium,radii[2]*2.01).limit(units[2])\n",
    "    ptsMediumSize= ptsMedium.size()\n",
    "    areasMedium = ptsMedium.reduceToImage(['nd'],ee.Reducer.first()).unmask(0).clip(aoi).reduceNeighborhood(ee.Reducer.max(),ee.Kernel.square(radii[2],'meters')).eq(1)\n",
    "    # mask prohibiting Small pts samples within overlap zone (Biggest,Big, and Medium areas plus buffer of twice small treatments radius)\n",
    "    blend2expmask = areasBiggest.add(areasBig).add(areasMedium).gte(1).distance(ee.Kernel.euclidean(radii[3]*2,'meters')).gte(0).Not().unmask(1).clip(aoi) \n",
    "\n",
    "    # Generate Small Treatmetns\n",
    "    ptsSmall = blend2expmask.selfMask().sample(aoi,SCALE,CRS,None,units[3]+(units[3]*10),seed,True,8,True).map(lambda f: f.set('nd',1))\n",
    "    ptsSmall = distanceFilter(ptsSmall,radii[3]*2.01).limit(units[3])\n",
    "    ptsSmallSize=ptsSmall.size()\n",
    "    areasSmall = ptsSmall.reduceToImage(['nd'],ee.Reducer.first()).unmask(0).clip(aoi).reduceNeighborhood(ee.Reducer.max(),ee.Kernel.square(radii[3],'meters')).eq(1)\n",
    "    \n",
    "    blendTreatments = areasBiggest.add(areasBig).add(areasMedium).add(areasSmall).gte(1).multiply(DIST_CODE).selfMask().rename('DIST').set('reqBiggestPts',units[0],\n",
    "                                                                                                                                          'actualBiggestPts',ptsBiggestSize,\n",
    "                                                                                                                                          'reqBigPts',units[1],\n",
    "                                                                                                                                          'actualBigPts',ptsBigSize,\n",
    "                                                                                                                                          'reqMediumPts',units[2],\n",
    "                                                                                                                                          'actualMediumPts',ptsMediumSize,\n",
    "                                                                                                                                          'reqSmallPts',units[3],\n",
    "                                                                                                                                          'actualSmallPts',ptsSmallSize)\n",
    "    \n",
    "    return blendTreatments\n",
    "    #return ptsBiggest,areasBiggest,areasBiggestmask,ptsBig,areasBig,blendmask,ptsMedium,areasMedium,blend2mask,ptsSmall,areasSmall,ee.Image(blendTreatments)\n",
    "\n",
    "def export_img(img,imgcoll_p,aoi):\n",
    "    \"\"\"Export image to imageCollection\"\"\"\n",
    "    desc = f\"scenario{ee.String(ee.Image(img).getNumber('scenario').format()).getInfo()}\"\n",
    "    \n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image=ee.Image(img),\n",
    "        description=desc,\n",
    "        assetId=f'{imgcoll_p}/{desc}', \n",
    "        region=aoi.geometry().bounds(), \n",
    "        scale=30, \n",
    "        crs='EPSG:5070', \n",
    "        maxPixels=1e13)\n",
    "\n",
    "    task.start()\n",
    "    print(f\"Export Started for {imgcoll_p}/{desc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0576d6f-47ed-445e-8b68-c94d8c382905",
   "metadata": {},
   "source": [
    "## Construct random treatment landscapes as rasters - format: an ee.Image exported to an ee.ImageCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f878a5-55d1-41c6-a512-dc9b1958601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Parameters: TOTAL_AREA (ac) = 245278; SCENARIO_PCT_RANGE = [0.05, 0.6]; DISTRO = norm; SIZE_CLASSES (ac) = [10, 40, 100, 400]\n",
      "First randomly generated scenario\n",
      "scenario pct area:  0.2585\n",
      "total area (ac) to treat:  63404.363000000005\n",
      "area per size class:  [19591.9482, 39120.492, 3931.0705, 760.8524]\n",
      "units per size class:  [1959, 978, 39, 2]\n",
      "radii per trt size:  [86.08908798448267, 172.17817596896535, 272.2375997175996, 544.4751994351992]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "pal = {'min':0,'max':1,'palette':['black','white']}\n",
    "\n",
    "\n",
    "# Run treatment math to construct your lists (length of SCENARIO) of the needed parameters\n",
    "scn,trt_areas,trt_props,units,radii = treatment_math(TOTAL_AREA,DISTRO,SCENARIO_PCT_RANGE,SCENARIOS,SIZE_CLASSES)\n",
    "\n",
    "print(f'Static Parameters: TOTAL_AREA (ac) = {TOTAL_AREA}; SCENARIO_PCT_RANGE = {SCENARIO_PCT_RANGE}; DISTRO = {DISTRO}; SIZE_CLASSES (ac) = {SIZE_CLASSES}')\n",
    "print('First randomly generated scenario')\n",
    "print('scenario pct area: ',scn[20])\n",
    "print('total area (ac) to treat: ', trt_areas[20])    \n",
    "print('area per size class: ',trt_props[20])\n",
    "print('units per size class: ', units[20])\n",
    "print('radii per trt size: ',radii[20])\n",
    "print('\\n')\n",
    "\n",
    "# for each scenario, make the treated landscape raster \n",
    "today_string = datetime.utcnow().strftime(\"%Y-%m-%d\").replace(\"-\", \"\")\n",
    "\n",
    "# make an ee.ImageCollection with specified path\n",
    "img_coll_p = f\"projects/aff-treatments/assets/scenarios_{SCENARIOS}_{today_string}\"\n",
    "os.popen(f\"earthengine create collection {img_coll_p}\").read()\n",
    "\n",
    "# trt_imgs = []\n",
    "# for i in list(range(SCENARIOS)):\n",
    "\n",
    "# ptsBiggest,areasBiggest,areasBiggestmask,ptsBig,areasBig,blendmask,ptsMedium,areasMedium,blend2mask,ptsSmall,areasSmall,trt_img = ee_treatments(units[20],radii[20]).set('scenario',i,\n",
    "#                                                                                                                                                                         'pct_Areatreated',scn[i])\n",
    "trt_img = ee_treatments(units[20],radii[20]).set('scenario',20,\n",
    "                                                'pct_Areatreated',scn[20])\n",
    "\n",
    "\n",
    "# print('Biggest trt points',ptsBiggest.size().getInfo())\n",
    "# print('Big trt points',ptsBig.size().getInfo())\n",
    "# print('Medium trt points',ptsMedium.size().getInfo())\n",
    "# print('Small trt points',ptsSmall.size().getInfo())\n",
    "\n",
    "# Map.addLayer(ptsBiggest, {}, 'pts Biggest')\n",
    "# Map.addLayer(areasBiggest, pal, 'biggest treatments')\n",
    "# Map.addLayer(areasBiggestmask,pal,'areasBiggestmask')\n",
    "\n",
    "# # Map.addLayer(ptsBig,{},'pts Big')\n",
    "# Map.addLayer(areasBig, pal, 'Big treatments')\n",
    "\n",
    "# Map.addLayer(blendmask,pal,'blendmask')\n",
    "\n",
    "\n",
    "\n",
    "# # Map.addLayer(ptsMedium, {}, 'pts Medium')\n",
    "# Map.addLayer(areasMedium,{},'Medium treatments')\n",
    "\n",
    "# Map.addLayer(blend2mask,pal,'blend2mask')\n",
    "\n",
    "# # Map.addLayer(ptsSmall, {}, 'pts Small')\n",
    "# Map.addLayer(areasSmall, pal, 'small treatments')\n",
    "# Map.addLayer(trt_img, pal,'final treatment landscape')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "export_img(trt_img,img_coll_p,aoi) #export image to image collection\n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "# # making one works..\n",
    "#trt_img_example = ee_treatments(units[5],radii[5]).set('scenario',5+1)\n",
    "# print(trt_img.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a9ab7-b2c8-4ab7-befc-a43516987d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(trt_img.getInfo()['properties'])\n",
    "#scn\n",
    "#print(seed)\n",
    "sum([9057.0128, 18084.7149, 1817.2647, 351.7287])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec22e43-f1d0-478a-90b8-c39e9fb5b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map = geemap.Map()\n",
    "\n",
    "# Map.addLayer(parcels,{},'parcels')\n",
    "# Map.addLayer(NIparcels,{},'NIP parcels')\n",
    "Map.addLayer(aoi,{},'AOI')\n",
    "Map.centerObject(aoi,12)\n",
    "pal = {'min':0,'max':1,'palette':['black','white']}\n",
    "\n",
    "#print(trt_imgs.first().propertyNames().getInfo())\n",
    "# Map.addLayer(trt_imgs.sort('scenario',False).first(), pal, 'final trt landscapes')\n",
    "Map.addLayer(trt_img, pal, 'first scenario')\n",
    "#Map.addLayer(trt_img_example, pal, 'other random scneario')\n",
    "\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbaa257-73cf-4d8f-8f67-04c03ce551a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
